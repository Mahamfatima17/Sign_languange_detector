# Sign_languange_detector
The ASL Translation System is a real-time computer vision application designed to interpret American Sign Language (ASL) using a standard webcam. It features two distinct detection pipelines: one for static letters (fingerspelling) and another for dynamic words and phrases.
# ğŸ¤Ÿ ASL Translation System

![Python 3.9](https://img.shields.io/badge/Python-3.9-blue)
![TensorFlow 2.10+](https://img.shields.io/badge/TensorFlow-2.10%2B-orange)
![MediaPipe 0.10.9](https://img.shields.io/badge/MediaPipe-0.10.9-green)
![Streamlit](https://img.shields.io/badge/Streamlit-1.28%2B-red)
[![GitHub Repo](https://img.shields.io/badge/GitHub-Repo-181717?logo=github)](https://github.com/Mahamfatima17/Sign_languange_detector)
![License MIT](https://img.shields.io/badge/License-MIT-yellow)

Real-time American Sign Language detection system using computer vision and deep learning. This project features two independent pipelines for recognizing static fingerspelling (letters) and dynamic signs (words/phrases).

## ğŸš€ Key Capabilities

- **ğŸ”¤ Static Letter Detection**: Real-time recognition of ASL alphabet (Aâ€“Y, excluding J/Z) using MediaPipe Hands and Random Forest.
- **ğŸ–ï¸ Dynamic Sign Detection**: Sequence recognition for words and phrases using MediaPipe Holistic and LSTM networks.
- **ğŸ“¹ Live Inference**: Interactive webcam feed with landmark visualization.
- **ğŸ“Š Confidence Scoring**: Real-time prediction probabilities and stabilization.
- **ğŸ”„ End-to-End Workflow**: Complete scripts for data collection, training, and inference.

---

## ğŸ› ï¸ Technologies Used

| Component | Technology | Description |
|-----------|-----------|-------------|
| **Hand Tracking** | MediaPipe Hands | Extracts 21 3D landmarks per hand |
| **Pose Estimator** | MediaPipe Holistic | Full-body tracking for dynamic signs |
| **Letter Classifier** | Scikit-learn | Random Forest for static poses |
| **Sign Classifier** | TensorFlow/Keras | LSTM for temporal sequence analysis |
| **UI Framework** | Streamlit | Web-based interface for real-time visualization |
| **Image Processing** | OpenCV | Frame capture and drawing utilities |

---

## ğŸ“‚ Project Structure

```
sign-language-detector/
â”œâ”€â”€ app.py                      # Main Streamlit app (Dynamic Signs + HUD)
â”œâ”€â”€ app_simple.py               # Lightweight Streamlit app (Static Letters)
â”œâ”€â”€ collect_letters.py          # Data collection for static letters
â”œâ”€â”€ train_letters.py            # Training script for letter model (Random Forest)
â”œâ”€â”€ batch_collect_data.py       # Data collection for dynamic signs
â”œâ”€â”€ train_model.py              # Training script for sign model (LSTM)
â”œâ”€â”€ LandmarkExtractor.py        # Helper for MediaPipe Holistic extraction
â”œâ”€â”€ SignModel.py                # LSTM model definition and utilities
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ run_app.sh                  # Helper script to launch the app
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ QUICKSTART.md               # Quick start guide
â””â”€â”€ models/                     # Directory for trained models
    â”œâ”€â”€ letter_model.pkl        # Trained Random Forest model
    â””â”€â”€ asl_model.h5            # Trained LSTM model
```

---

## âš¡ Installation

### Prerequisites
- Python 3.9 (Recommended for MediaPipe compatibility)
- Webcam

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/Mahamfatima17/Sign_languange_detector.git
   cd Sign_languange_detector
   ```

2. **Create a virtual environment**
   ```bash
   # Windows
   python -m venv .venv
   .venv\Scripts\activate

   # macOS/Linux
   python3 -m venv .venv
   source .venv/bin/activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

---

## ğŸ“– Usage

### Option A: Static Letter Detection (Quick Start)

1. **Collect Data** (Optional if using pre-trained model)
   ```bash
   python collect_letters.py
   ```
   *Press `SPACE` to capture, `N`/`P` to change letters, `Q` to quit.*

2. **Train Model**
   ```bash
   python train_letters.py
   ```

3. **Run App**
   ```bash
   streamlit run app_simple.py
   ```

### Option B: Dynamic Sign Detection (Advanced)

1. **Collect Data**
   ```bash
   python batch_collect_data.py
   ```
   *Follow on-screen prompts to record 30 frames per sign.*

2. **Train Model**
   ```bash
   python train_model.py
   ```

3. **Run App**
   ```bash
   streamlit run app.py
   ```

---

## ğŸ§  Model Details

### 1. Static Letter Model
- **Input**: 63 normalized hand landmark coordinates (x, y, z).
- **Algorithm**: Random Forest Classifier.
- **Performance**: High accuracy (~95%+) on static poses with minimal latency.

### 2. Dynamic Sign Model
- **Input**: Sequence of 30 frames Ã— 1662 landmarks (Pose + Face + Hands).
- **Architecture**:
  - `LSTM` (64 units) â†’ `Dropout`
  - `LSTM` (128 units) â†’ `Dropout`
  - `Dense` (64 units, ReLU)
  - `Dense` (Softmax)
- **Features**: Translates temporal movement patterns into sign predictions.

---

## ğŸ”§ Troubleshooting

- **MediaPipe Errors**: Ensure you use `mediapipe==0.10.9`. Newer versions may have API changes.
- **Camera Issues**: If the camera doesn't open, try changing the `camera_index` in `app.py` or the sidebar settings.
- **Low Accuracy**: Ensure good lighting and keep your hand within the frame. Re-collecting data with your own hand usually improves performance significantly.

---

## ğŸ“œ License

Distributed under the MIT License. See `LICENSE` for more information.

---

## ğŸ¤ Acknowledgments

- Built using [MediaPipe](https://mediapipe.dev/) and [Streamlit](https://streamlit.io/).
- Inspired by various open-source ASL recognition projects.
